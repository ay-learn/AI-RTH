\begin{frame}{Les Problème de IA}
    \begin{enumerate}[<+-|alert@+>]
        \myitem Les erreurs
        \myitem Boit noir
        \myitem Les probleme philosofique
    \end{enumerate}
       \only<1>{
            % \vspace{-10mm}
            \begin{exampleblock} {Les erreurs:}
                Les systèmes d’intelligence artificielle peuvent être défaillants et provoquer
                une interruption de l’activité (pertes de données, erreurs, informations
                incohérentes, etc.).
            \end{exampleblock}
        }
        \only<2>{
            % \vspace{-10mm}
            \begin{exampleblock}{Boit noir:}
                Les approches numériques s'apparentent en revanche à une boîte
                noire, incapable de justifier ses décisions : nul ne sait ce que
                fait l'algorithme. Comment, dès lors, endosser la responsabilité
                de la décision médicale ? Les données d'apprentissage sont en
                particulier biaisées par les préjugés de l'époque et ceux des
                concepteurs.
            \end{exampleblock}
        }
        \only<3>{
            \begin{exampleblock} {Les probleme philosofique:}
                Les tenants de l'intelligence artificielle dite forte visent à
                concevoir une machine capable de raisonner comme l'humain, avec le
                risque supposé de générer une machine supérieure à l'Homme et dotée
                d'une conscience propre. Cette voie de recherche est toujours explorée
                aujourd'hui, même si de nombreux chercheurs en IA estiment
                qu'atteindre un tel objectif est impossible.
            \end{exampleblock}
        }
    \vspace{80mm}
\end{frame}
